[dataset]
# MNIST, FashionMNIST, CIFAR10, ImageNet,
dataset = ImageNet
batch_size = 100

[model]
# ResNet for MNIST, FashionMNIST, CIFAR10, ImageNet
# model in torchvision.models for ImageNet
model = mobilenet_v2
retrain = 0
test = 1

[data_sampling]
# sampling
# Select the sampling method:
# 0: random sampling: randomly sampling uniformly.
# 1: balance sampling: sampling the same number of data from each label;
sampling = 1

# total number of samples for generating adversarial_examples
batch_train_natural_samples = 60
batch_train_adversarial_samples = 60
batch_test_natural_samples = 10
batch_test_adversarial_samples = 10

[generator]
# adversarial generator
num_train = 6000
num_test = 1000

[attack]
# attack_method: Check https://github.com/Harry24k/adversarial-attacks-pytorch to see what attack method we already offer;
train_attack_method = FGSM
test_attack_method = FGSM
[train_attack_parameters]
# parameter for attack: different attack_method have different parameters. Write one line for each parameter 
# FGSM:{eps: perturbation level}
eps = 0.0627
# iFGSM:{}
# CarliniWagnerL0
# CarliniWagnerL2
# c = 2

# CarliniWagnerL

[test_attack_parameters]
# parameter for attack: different attack_method have different parameters
# FGSM:{eps: perturbation level}
eps = 0.0627
# iFGSM:{}
# CarliniWagnerL0
# CarliniWagnerL2
# c = 2

[squeezer]
s1 = ColorDepthSqueezer
s2 = ColorDepthSqueezer
[squeezer_parameters_s1]
s = 32
[squeezer_parameters_s2]
s = 64

[classifier]
c1 = LinearClassifier
c2 = LinearClassifier
# c1 = ImageNetClassifier
# c2 = ImageNetClassifier
# c1 = NNClassifier
# c2 = NNClassifier
[classifier_parameters_c1]
# learning_rate = 2e-4
# epoch = 10
[classifier_parameters_c2]
# learning_rate = 2e-4
# epoch = 10

[detector]
# Hawkeye
# name = Hawkeye
name = FeatureSqueezing

